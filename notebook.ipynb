{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_test=[]  \n",
    "dfs_train=[]   \n",
    "\n",
    "#For bending1\n",
    "filepath= 'AReM/bending1'\n",
    "files=glob.glob(os.path.join(filepath,\"*.csv\"))\n",
    "\n",
    "for i in files:\n",
    "    if (i==\"AReM/bending1/dataset1.csv\") or (i==\"AReM/bending1/dataset2.csv\"):\n",
    "        df=pd.read_csv(i, skiprows=4)\n",
    "        dfs_test.append(df)\n",
    "    else:\n",
    "        df=pd.read_csv(i, skiprows=4)\n",
    "        dfs_train.append(df)\n",
    "        \n",
    "#for bending2\n",
    "filepath2= 'AReM/bending2'\n",
    "files=glob.glob(os.path.join(filepath2,\"*.csv\"))\n",
    "\n",
    "for i in files:\n",
    "    if (i==\"AReM/bending2/dataset1.csv\") or (i==\"AReM/bending2/dataset2.csv\"):\n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        dfs_test.append(df)\n",
    "        \n",
    "    elif (i==\"AReM/bending2/dataset4.csv\"):\n",
    "        dfs=pd.read_csv(i,sep=' ',skiprows=5,names=[\"# Columns: time\",\"avg_rss12\",\"var_rss12\",\"avg_rss13\",\"var_rss13\",\"avg_rss23\",\"var_rss23\"],index_col=False)\n",
    "        dfs_train.append(dfs)\n",
    "    else:\n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        dfs_train.append(df)\n",
    "        \n",
    "#For cycling\n",
    "file_cycle= 'AReM/cycling'\n",
    "files=glob.glob(os.path.join(file_cycle,\"*.csv\"))\n",
    "\n",
    "for i in files:\n",
    "    if ((i==\"AReM/cycling/dataset1.csv\") or (i==\"AReM/cycling/dataset2.csv\") or(i==\"AReM/cycling/dataset3.csv\")):\n",
    "        \n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        dfs_test.append(df)\n",
    "    else:\n",
    "        dfs=pd.read_csv(i,skiprows=5, sep=' ',names=[\"# Columns: time\",\"avg_rss12\",\"var_rss12\",\"avg_rss13\",\"var_rss13\",\"avg_rss23\",\"var_rss23\"],index_col=False)\n",
    "        dfs_train.append(dfs)\n",
    "\n",
    "        \n",
    "#For lying dataset\n",
    "file_lying= 'AReM/lying'\n",
    "files=glob.glob(os.path.join(file_lying,\"*.csv\"))\n",
    " \n",
    "\n",
    "for i in files:\n",
    "    if ((i==\"AReM/lying/dataset1.csv\") or (i==\"AReM/lying/dataset2.csv\") or (i==\"AReM/lying/dataset3.csv\")):\n",
    "        \n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        \n",
    "        dfs_test.append(df)\n",
    "    else:\n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        \n",
    "        dfs_train.append(df)\n",
    "\n",
    "#For sitting\n",
    "file_sitting= 'AReM/sitting'\n",
    "files=glob.glob(os.path.join(file_sitting,\"*.csv\"))\n",
    " \n",
    "\n",
    "for i in files:\n",
    "    if ((i==\"AReM/sitting/dataset1.csv\") or (i==\"AReM/sitting/dataset2.csv\") or (i==\"AReM/sitting/dataset3.csv\")):\n",
    "        \n",
    "        df=pd.read_csv(i ,skiprows=4)\n",
    "        \n",
    "        dfs_test.append(df)\n",
    "    else:\n",
    "        df=pd.read_csv(i ,skiprows=4)\n",
    "        \n",
    "        dfs_train.append(df)\n",
    "\n",
    "#For standing\n",
    "file_standing= 'AReM/standing'\n",
    "files=glob.glob(os.path.join(file_standing,\"*.csv\"))\n",
    " \n",
    "\n",
    "for i in files:\n",
    "    if ((i==\"AReM/standing/dataset1.csv\") or (i==\"AReM/standing/dataset2.csv\") or (i==\"AReM/standing/dataset3.csv\")):\n",
    "        df = pd.read_csv(i, skiprows=4)\n",
    "        \n",
    "        dfs_test.append(df)\n",
    "    else:\n",
    "        df=pd.read_csv(i, skiprows=4)\n",
    "        \n",
    "        dfs_train.append(df)\n",
    "        \n",
    "#For walking \n",
    "file_walking= 'AReM/walking'\n",
    "files=glob.glob(os.path.join(file_walking,\"*.csv\"))\n",
    " \n",
    "\n",
    "for i in files:\n",
    "    if ((i==\"AReM/walking/dataset1.csv\") or (i==\"AReM/walking/dataset2.csv\") or (i==\"AReM/walking/dataset3.csv\")):\n",
    "        \n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        \n",
    "        dfs_test.append(df)\n",
    "    else:\n",
    "        df=pd.read_csv(i,skiprows=4)\n",
    "        \n",
    "        dfs_train.append(df)             \n",
    "\n",
    "dfs_test=pd.concat(dfs_test,axis=0,ignore_index=True)\n",
    "dfs_train=pd.concat(dfs_train,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Columns: time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Columns: time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0                0      39.25       0.43      22.75       0.43      33.75   \n",
       "1              250      39.25       0.43      23.00       0.00      33.00   \n",
       "2              500      39.25       0.43      23.25       0.43      33.00   \n",
       "3              750      39.50       0.50      23.00       0.71      33.00   \n",
       "4             1000      39.50       0.50      24.00       0.00      33.00   \n",
       "\n",
       "   var_rss23  \n",
       "0        1.3  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9120, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Columns: time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>42.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>16.75</td>\n",
       "      <td>1.79</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>42.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Columns: time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0               0      42.00       0.00      18.50       0.50      12.00   \n",
       "1             250      42.00       0.00      18.00       0.00      11.33   \n",
       "2             500      42.75       0.43      16.75       1.79      18.25   \n",
       "3             750      42.50       0.50      16.75       0.83      19.00   \n",
       "4            1000      43.00       0.82      16.25       0.83      18.00   \n",
       "\n",
       "   var_rss23  \n",
       "0       0.00  \n",
       "1       0.94  \n",
       "2       0.43  \n",
       "3       1.22  \n",
       "4       0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33119, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-domain features are often used in time series classification to extract useful information about the temporal characteristics of a signal. \n",
    "\n",
    "1. Min - Minimum \n",
    "2. Max - Maximum\n",
    "3. Mean - the average value of the signal over time.\n",
    "4. Standard deviation - a measure of the spread of the signal values.\n",
    "5. Median - the middle value of the signal.\n",
    "6. Interquartile range - the range between the 25th and 75th percentile of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coloums=[]\n",
    "for k in range(1,7):\n",
    "    coloums.append(['min'+str(k),'max'+str(k),'mean'+str(k),'median'+str(k),'std'+str(k),'1st quart'+str(k),'3rd quart'+str(k)])\n",
    "fnl_coloumn = [item for sublist in coloums for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bending1=[]\n",
    "for k in range(1,8):\n",
    "    bending1.append(\"dataset\"+str(k))\n",
    "    \n",
    "filepath_bend= 'AReM/bending1'\n",
    "files=glob.glob(os.path.join(filepath_bend,\"*.csv\"))\n",
    "\n",
    "df_final= pd.DataFrame(columns=[fnl_coloumn])\n",
    "for i in bending1:\n",
    "    df=pd.read_csv(filepath_bend+'/' + str(i)+\".csv\",skiprows=4)\n",
    "    df.drop(columns=['# Columns: time'],axis=1)\n",
    "    temp=[]\n",
    "    for j in df.columns[1:]:\n",
    "        temp.append(df[j].min())\n",
    "        temp.append(df[j].max())\n",
    "        temp.append(df[j].mean())\n",
    "        temp.append(df[j].median())\n",
    "        temp.append(df[j].std())\n",
    "        temp.append(df[j].quantile(0.25))\n",
    "        temp.append(df[j].quantile(0.75))\n",
    "        \n",
    "    df_final.loc[len(df_final)]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bending2=[]\n",
    "for k in range(1,7):\n",
    "    bending2.append(\"dataset\"+str(k))\n",
    "\n",
    "\n",
    "filepath_bend2= 'AReM/bending2'\n",
    "files=glob.glob(os.path.join(filepath_bend2,\"*.csv\"))\n",
    "\n",
    "df_final2= pd.DataFrame(columns=[fnl_coloumn])\n",
    "\n",
    "for i in bending2:\n",
    "    temp2=[]\n",
    "    if i == 'dataset4':\n",
    "        path=\"AReM/bending2/\"+str(i)+\".csv\"\n",
    "        df_bend2=pd.read_csv(path,sep=' ',skiprows=5,names=[\"# Columns: time\",\"avg_rss12\",\"var_rss12\",\"avg_rss13\",\"var_rss13\",\"avg_rss23\",\"var_rss23\"],index_col=False)  \n",
    "        for j in df_bend2.columns[1:]:\n",
    "            temp2.append(df_bend2[j].min())\n",
    "            temp2.append(df_bend2[j].max())\n",
    "            temp2.append(df_bend2[j].mean())\n",
    "            temp2.append(df_bend2[j].median())\n",
    "            temp2.append(df_bend2[j].std())\n",
    "            temp2.append(df_bend2[j].quantile(0.25))\n",
    "            temp2.append(df_bend2[j].quantile(0.75))\n",
    "    else:\n",
    "        df_bend2=pd.read_csv(filepath_bend2+'/' + str(i)+\".csv\",skiprows=4)\n",
    "        for j in df_bend2.columns[1:]:\n",
    "            temp2.append(df_bend2[j].min())\n",
    "            temp2.append(df_bend2[j].max())\n",
    "            temp2.append(df_bend2[j].mean())\n",
    "            temp2.append(df_bend2[j].median())\n",
    "            temp2.append(df_bend2[j].std())\n",
    "            temp2.append(df_bend2[j].quantile(0.25))\n",
    "            temp2.append(df_bend2[j].quantile(0.75))\n",
    "            \n",
    "    \n",
    "    df_final2.loc[len(df_final2)]=temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling=[]\n",
    "for k in range(1,16):\n",
    "    cycling.append(\"dataset\"+str(k))\n",
    "    \n",
    "filepath_cyc= 'AReM/cycling'\n",
    "files=glob.glob(os.path.join(filepath_cyc,\"*.csv\"))\n",
    "\n",
    "\n",
    "df_final_cyc= pd.DataFrame(columns=[fnl_coloumn])\n",
    "\n",
    "for i in cycling:\n",
    "    temp_cyc=[]\n",
    "    \n",
    "    if i!='dataset1'or i!='dataset2' or i!='dataset3':\n",
    "        path=\"AReM/cycling/\"+str(i)+\".csv\"\n",
    "        df_cyc=pd.read_csv(path, sep=' ',skiprows=5, names=[\"# Columns: time\",\"avg_rss12\",\"var_rss12\",\"avg_rss13\",\"var_rss13\",\"avg_rss23\",\"var_rss23\"],index_col=False)\n",
    "        for j in df_cyc.columns[1:]:\n",
    "            temp_cyc.append(df_cyc[j].min())\n",
    "            temp_cyc.append(df_cyc[j].max())\n",
    "            temp_cyc.append(df_cyc[j].mean())\n",
    "            temp_cyc.append(df_cyc[j].median())\n",
    "            temp_cyc.append(df_cyc[j].std())\n",
    "            temp_cyc.append(df_cyc[j].quantile(0.25))\n",
    "            temp_cyc.append(df_cyc[j].quantile(0.75))\n",
    "    else:\n",
    "        df_cyc=pd.read_csv(filepath_cyc+'/' + str(i)+\".csv\",skiprows=4)\n",
    "        for j in df_cyc.columns[1:]:\n",
    "            temp_cyc.append(df_cyc[j].min())\n",
    "            temp_cyc.append(df_cyc[j].max())\n",
    "            temp_cyc.append(df_cyc[j].mean())\n",
    "            temp_cyc.append(df_cyc[j].median())\n",
    "            temp_cyc.append(df_cyc[j].std())\n",
    "            temp_cyc.append(df_cyc[j].quantile(0.25))\n",
    "            temp_cyc.append(df_cyc[j].quantile(0.75))\n",
    "    \n",
    "        \n",
    "       \n",
    "    df_final_cyc.loc[len(df_final_cyc)]=temp_cyc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lying=[]\n",
    "for k in range(1,16):\n",
    "    lying.append(\"dataset\"+str(k))\n",
    "\n",
    "filepath_ly= 'AReM/lying'\n",
    "files=glob.glob(os.path.join(filepath_ly,\"*.csv\"))\n",
    "\n",
    "df_final_ly= pd.DataFrame(columns=[fnl_coloumn])\n",
    "for i in cycling:\n",
    "    df_ly=pd.read_csv(filepath_ly+'/' + str(i)+\".csv\",skiprows=4)\n",
    "    temp_ly=[]\n",
    "    for j in df_cyc.columns[1:]:\n",
    "        temp_ly.append(df_ly[j].min())\n",
    "        temp_ly.append(df_ly[j].max())\n",
    "        temp_ly.append(df_ly[j].mean())\n",
    "        temp_ly.append(df_ly[j].median())\n",
    "        temp_ly.append(df_ly[j].std())\n",
    "        temp_ly.append(df_ly[j].quantile(0.25))\n",
    "        temp_ly.append(df_ly[j].quantile(0.75))\n",
    "    \n",
    "       \n",
    "    df_final_ly.loc[len(df_final_ly)]=temp_ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitting=[]\n",
    "for k in range(1,16):\n",
    "    sitting.append(\"dataset\"+str(k))\n",
    "\n",
    "filepath_sit= 'AReM/sitting'\n",
    "files=glob.glob(os.path.join(filepath_sit,\"*.csv\"))\n",
    "\n",
    "\n",
    "df_final_sit= pd.DataFrame(columns=[fnl_coloumn])\n",
    "for i in sitting:\n",
    "    df_sit=pd.read_csv(filepath_sit+'/' + str(i)+\".csv\",skiprows=4)\n",
    "    temp_sit=[]\n",
    "    for j in df_sit.columns[1:]:\n",
    "        temp_sit.append(df_sit[j].min())\n",
    "        temp_sit.append(df_sit[j].max())\n",
    "        temp_sit.append(df_sit[j].mean())\n",
    "        temp_sit.append(df_sit[j].median())\n",
    "        temp_sit.append(df_sit[j].std())\n",
    "        temp_sit.append(df_sit[j].quantile(0.25))\n",
    "        temp_sit.append(df_sit[j].quantile(0.75))\n",
    "    \n",
    "        \n",
    "    df_final_sit.loc[len(df_final_sit)]=temp_sit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "standing=[]\n",
    "for k in range(1,16):\n",
    "    standing.append(\"dataset\"+str(k))\n",
    "\n",
    "filepath_stan= 'AReM/standing'\n",
    "files=glob.glob(os.path.join(filepath_stan,\"*.csv\"))\n",
    "\n",
    "\n",
    "df_final_stan= pd.DataFrame(columns=[fnl_coloumn])\n",
    "for i in standing:\n",
    "    df_stan=pd.read_csv(filepath_stan+'/' + str(i)+\".csv\",skiprows=4)\n",
    "    temp_stan=[]\n",
    "    for j in df_stan.columns[1:]:\n",
    "        temp_stan.append(df_stan[j].min())\n",
    "        temp_stan.append(df_stan[j].max())\n",
    "        temp_stan.append(df_stan[j].mean())\n",
    "        temp_stan.append(df_stan[j].median())\n",
    "        temp_stan.append(df_stan[j].std())\n",
    "        temp_stan.append(df_stan[j].quantile(0.25))\n",
    "        temp_stan.append(df_stan[j].quantile(0.75))\n",
    "        \n",
    "    \n",
    "    df_final_stan.loc[len(df_final_stan)]=temp_stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking=[]\n",
    "for k in range(1,16):\n",
    "    walking.append(\"dataset\"+str(k))\n",
    "\n",
    "filepath_walk= 'AReM/walking'\n",
    "files=glob.glob(os.path.join(filepath_walk,\"*.csv\"))\n",
    "\n",
    "\n",
    "df_final_walk= pd.DataFrame(columns=[fnl_coloumn])\n",
    "for i in walking:\n",
    "    df_walk=pd.read_csv(filepath_walk+'/' + str(i)+\".csv\",skiprows=4)\n",
    "    temp_walk=[]\n",
    "    for j in df_walk.columns[1:]:\n",
    "        temp_walk.append(df_walk[j].min())\n",
    "        temp_walk.append(df_walk[j].max())\n",
    "        temp_walk.append(df_walk[j].mean())\n",
    "        temp_walk.append(df_walk[j].median())\n",
    "        temp_walk.append(df_walk[j].std())\n",
    "        temp_walk.append(df_walk[j].quantile(0.25))\n",
    "        temp_walk.append(df_walk[j].quantile(0.75))\n",
    "        \n",
    "    \n",
    "    df_final_walk.loc[len(df_final_walk)]=temp_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[df_final,df_final2,df_final_cyc,df_final_ly,df_final_sit,df_final_stan,df_final_walk]\n",
    "final_df= pd.concat(frames,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st quart1</th>\n",
       "      <th>3rd quart1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st quart5</th>\n",
       "      <th>3rd quart5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st quart6</th>\n",
       "      <th>3rd quart6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.50</td>\n",
       "      <td>1.435550</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.372438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995255</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.558835</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999604</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.513506</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.50</td>\n",
       "      <td>3.670666</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.696042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.849448</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.75</td>\n",
       "      <td>2.243490</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411026</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.389164</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>19.50</td>\n",
       "      <td>45.33</td>\n",
       "      <td>33.586875</td>\n",
       "      <td>34.25</td>\n",
       "      <td>4.650935</td>\n",
       "      <td>30.25</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.67</td>\n",
       "      <td>4.576562</td>\n",
       "      <td>...</td>\n",
       "      <td>3.283983</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.32</td>\n",
       "      <td>3.259729</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.640243</td>\n",
       "      <td>2.0500</td>\n",
       "      <td>4.3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.75</td>\n",
       "      <td>45.50</td>\n",
       "      <td>34.322750</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.752477</td>\n",
       "      <td>31.00</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.47</td>\n",
       "      <td>4.456333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.119856</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>3.432562</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.1575</td>\n",
       "      <td>4.5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>19.50</td>\n",
       "      <td>46.00</td>\n",
       "      <td>34.546229</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.842294</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.47</td>\n",
       "      <td>4.371958</td>\n",
       "      <td>...</td>\n",
       "      <td>2.823124</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.338125</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.656742</td>\n",
       "      <td>2.1600</td>\n",
       "      <td>4.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>23.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.873229</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.531720</td>\n",
       "      <td>31.75</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>4.380583</td>\n",
       "      <td>...</td>\n",
       "      <td>3.131076</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.51</td>\n",
       "      <td>3.424646</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.690960</td>\n",
       "      <td>2.1700</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>19.25</td>\n",
       "      <td>44.00</td>\n",
       "      <td>34.473188</td>\n",
       "      <td>35.00</td>\n",
       "      <td>4.796705</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.86</td>\n",
       "      <td>4.359312</td>\n",
       "      <td>...</td>\n",
       "      <td>3.156320</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.340458</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1.699114</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     min1   max1      mean1 median1      std1 1st quart1 3rd quart1 min2  \\\n",
       "0   37.25  45.00  40.624792   40.50  1.476967      39.25    42.0000  0.0   \n",
       "1   38.00  45.67  42.812812   42.50  1.435550      42.00    43.6700  0.0   \n",
       "2   35.00  47.40  43.954500   44.33  1.558835      43.00    45.0000  0.0   \n",
       "3   33.00  47.75  42.179813   43.50  3.670666      39.15    45.0000  0.0   \n",
       "4   33.00  45.75  41.678063   41.75  2.243490      41.33    42.7500  0.0   \n",
       "..    ...    ...        ...     ...       ...        ...        ...  ...   \n",
       "83  19.50  45.33  33.586875   34.25  4.650935      30.25    37.0000  0.0   \n",
       "84  19.75  45.50  34.322750   35.25  4.752477      31.00    38.0000  0.0   \n",
       "85  19.50  46.00  34.546229   35.25  4.842294      31.25    37.8125  0.0   \n",
       "86  23.50  46.25  34.873229   35.25  4.531720      31.75    38.2500  0.0   \n",
       "87  19.25  44.00  34.473188   35.00  4.796705      31.25    38.0000  0.0   \n",
       "\n",
       "     max2     mean2  ...      std5 1st quart5 3rd quart5  min6   max6  \\\n",
       "0    1.30  0.358604  ...  2.188449    33.0000      36.00  0.00   1.92   \n",
       "1    1.22  0.372438  ...  1.995255    32.0000      34.50  0.00   3.11   \n",
       "2    1.70  0.426250  ...  1.999604    35.3625      36.50  0.00   1.79   \n",
       "3    3.00  0.696042  ...  3.849448    30.4575      36.33  0.00   2.18   \n",
       "4    2.83  0.535979  ...  2.411026    28.4575      31.25  0.00   1.79   \n",
       "..    ...       ...  ...       ...        ...        ...   ...    ...   \n",
       "83  14.67  4.576562  ...  3.283983    13.7300      18.25  0.00   8.32   \n",
       "84  13.47  4.456333  ...  3.119856    13.5000      17.75  0.00   9.67   \n",
       "85  12.47  4.371958  ...  2.823124    14.0000      17.75  0.00  10.00   \n",
       "86  14.82  4.380583  ...  3.131076    13.7500      18.00  0.00   9.51   \n",
       "87  13.86  4.359312  ...  3.156320    13.7300      17.75  0.43   9.00   \n",
       "\n",
       "       mean6 median6      std6 1st quart6 3rd quart6  \n",
       "0   0.570583    0.43  0.582915     0.0000     1.3000  \n",
       "1   0.571083    0.43  0.601010     0.0000     1.3000  \n",
       "2   0.493292    0.43  0.513506     0.0000     0.9400  \n",
       "3   0.613521    0.50  0.524317     0.0000     1.0000  \n",
       "4   0.383292    0.43  0.389164     0.0000     0.5000  \n",
       "..       ...     ...       ...        ...        ...  \n",
       "83  3.259729    3.11  1.640243     2.0500     4.3225  \n",
       "84  3.432562    3.20  1.732727     2.1575     4.5650  \n",
       "85  3.338125    3.08  1.656742     2.1600     4.3350  \n",
       "86  3.424646    3.27  1.690960     2.1700     4.5000  \n",
       "87  3.340458    3.09  1.699114     2.1200     4.3750  \n",
       "\n",
       "[88 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st quart1</th>\n",
       "      <th>3rd quart1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st quart5</th>\n",
       "      <th>3rd quart5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st quart6</th>\n",
       "      <th>3rd quart6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.028750</td>\n",
       "      <td>45.852500</td>\n",
       "      <td>39.494976</td>\n",
       "      <td>39.528681</td>\n",
       "      <td>2.851116</td>\n",
       "      <td>37.747049</td>\n",
       "      <td>41.625104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.413750</td>\n",
       "      <td>1.219736</td>\n",
       "      <td>...</td>\n",
       "      <td>3.669400</td>\n",
       "      <td>13.436597</td>\n",
       "      <td>18.294826</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>5.897500</td>\n",
       "      <td>1.338316</td>\n",
       "      <td>1.191181</td>\n",
       "      <td>0.910394</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>1.764479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.216682</td>\n",
       "      <td>4.590553</td>\n",
       "      <td>5.687615</td>\n",
       "      <td>5.763545</td>\n",
       "      <td>1.903009</td>\n",
       "      <td>6.559536</td>\n",
       "      <td>5.484257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.029536</td>\n",
       "      <td>1.616355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071936</td>\n",
       "      <td>6.653618</td>\n",
       "      <td>6.066314</td>\n",
       "      <td>0.050676</td>\n",
       "      <td>2.405443</td>\n",
       "      <td>1.052155</td>\n",
       "      <td>1.009821</td>\n",
       "      <td>0.445189</td>\n",
       "      <td>0.723208</td>\n",
       "      <td>1.380138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.562958</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>23.187500</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.542500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.388372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>34.586464</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>1.440578</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.363688</td>\n",
       "      <td>...</td>\n",
       "      <td>3.075863</td>\n",
       "      <td>10.421875</td>\n",
       "      <td>15.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.240000</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608510</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.290000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>42.145698</td>\n",
       "      <td>41.625000</td>\n",
       "      <td>2.389754</td>\n",
       "      <td>39.875000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.055000</td>\n",
       "      <td>0.445198</td>\n",
       "      <td>...</td>\n",
       "      <td>3.303720</td>\n",
       "      <td>13.615000</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.737295</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.062500</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>43.521224</td>\n",
       "      <td>43.835000</td>\n",
       "      <td>4.671149</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.585411</td>\n",
       "      <td>...</td>\n",
       "      <td>4.116093</td>\n",
       "      <td>14.812500</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.377500</td>\n",
       "      <td>1.156823</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.039654</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>48.004167</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>7.684146</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>4.576562</td>\n",
       "      <td>...</td>\n",
       "      <td>7.853427</td>\n",
       "      <td>35.362500</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>3.500750</td>\n",
       "      <td>3.285000</td>\n",
       "      <td>1.792090</td>\n",
       "      <td>2.240000</td>\n",
       "      <td>4.565000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            min1       max1      mean1    median1       std1 1st quart1  \\\n",
       "count  72.000000  72.000000  72.000000  72.000000  72.000000  72.000000   \n",
       "mean   30.028750  45.852500  39.494976  39.528681   2.851116  37.747049   \n",
       "std    10.216682   4.590553   5.687615   5.763545   1.903009   6.559536   \n",
       "min     0.000000  30.000000  24.562958  24.250000   0.032038  23.187500   \n",
       "25%    21.500000  45.000000  34.586464  35.250000   1.440578  31.250000   \n",
       "50%    33.290000  46.250000  42.145698  41.625000   2.389754  39.875000   \n",
       "75%    37.062500  48.000000  43.521224  43.835000   4.671149  42.000000   \n",
       "max    48.000000  56.250000  48.004167  48.000000   7.684146  48.000000   \n",
       "\n",
       "      3rd quart1  min2       max2      mean2  ...       std5 1st quart5  \\\n",
       "count  72.000000  72.0  72.000000  72.000000  ...  72.000000  72.000000   \n",
       "mean   41.625104   0.0   5.413750   1.219736  ...   3.669400  13.436597   \n",
       "std     5.484257   0.0   5.029536   1.616355  ...   1.071936   6.653618   \n",
       "min    26.500000   0.0   0.430000   0.007167  ...   1.995255   1.000000   \n",
       "25%    38.000000   0.0   1.560000   0.363688  ...   3.075863  10.421875   \n",
       "50%    43.000000   0.0   3.055000   0.445198  ...   3.303720  13.615000   \n",
       "75%    45.000000   0.0   8.490000   0.585411  ...   4.116093  14.812500   \n",
       "max    54.000000   0.0  17.240000   4.576562  ...   7.853427  35.362500   \n",
       "\n",
       "      3rd quart5       min6       max6      mean6    median6       std6  \\\n",
       "count  72.000000  72.000000  72.000000  72.000000  72.000000  72.000000   \n",
       "mean   18.294826   0.005972   5.897500   1.338316   1.191181   0.910394   \n",
       "std     6.066314   0.050676   2.405443   1.052155   1.009821   0.445189   \n",
       "min     5.542500   0.000000   1.790000   0.383292   0.430000   0.388372   \n",
       "25%    15.437500   0.000000   4.240000   0.698333   0.500000   0.608510   \n",
       "50%    18.125000   0.000000   5.720000   0.862506   0.820000   0.737295   \n",
       "75%    20.000000   0.000000   7.377500   1.156823   0.940000   1.039654   \n",
       "max    36.500000   0.430000  13.610000   3.500750   3.285000   1.792090   \n",
       "\n",
       "      1st quart6 3rd quart6  \n",
       "count  72.000000  72.000000  \n",
       "mean    0.737500   1.764479  \n",
       "std     0.723208   1.380138  \n",
       "min     0.000000   0.500000  \n",
       "25%     0.430000   0.947500  \n",
       "50%     0.460000   1.120000  \n",
       "75%     0.500000   1.350000  \n",
       "max     2.240000   4.565000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min1          10.216682\n",
       "max1           4.590553\n",
       "mean1          5.687615\n",
       "median1        5.763545\n",
       "std1           1.903009\n",
       "1st quart1     6.559536\n",
       "3rd quart1     5.484257\n",
       "min2           0.000000\n",
       "max2           5.029536\n",
       "mean2          1.616355\n",
       "median2        1.480532\n",
       "std2           0.857901\n",
       "1st quart2     0.997428\n",
       "3rd quart2     2.161815\n",
       "min3           2.836313\n",
       "max3           4.967620\n",
       "mean3          4.229650\n",
       "median3        4.307799\n",
       "std3           1.039738\n",
       "1st quart3     4.492750\n",
       "3rd quart3     4.438369\n",
       "min4           0.000000\n",
       "max4           2.029274\n",
       "mean4          1.046196\n",
       "median4        1.033202\n",
       "std4           0.388417\n",
       "1st quart4     0.795318\n",
       "3rd quart4     1.378237\n",
       "min5           6.562029\n",
       "max5           6.327583\n",
       "mean5          6.209927\n",
       "median5        6.360592\n",
       "std5           1.071936\n",
       "1st quart5     6.653618\n",
       "3rd quart5     6.066314\n",
       "min6           0.050676\n",
       "max6           2.405443\n",
       "mean6          1.052155\n",
       "median6        1.009821\n",
       "std6           0.445189\n",
       "1st quart6     0.723208\n",
       "3rd quart6     1.380138\n",
       "Name: std, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds = final_df.describe().loc[\"std\"]\n",
    "stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_interval=pd.DataFrame(columns=[\"The features\",\"90% confidence interval\"])\n",
    "conf_intrvl=[]\n",
    "conf_interval[\"The features\"] =fnl_coloumn \n",
    "\n",
    "for i in range (0,len(final_df.columns)):\n",
    "  # samples must be in a sequence\n",
    "    res = bootstrap((final_df.iloc[:,i],), np.std, confidence_level=0.9,random_state=20, method='percentile')\n",
    "    conf_intrvl.append(res.confidence_interval)\n",
    "\n",
    "conf_interval[\"90% confidence interval\"]=pd.Series(conf_intrvl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to me the most important features are namely Standard Deviation, median, and mean. the most important features to seem like mean, median and standard deviation.\n",
    "\n",
    "1) Standard Deviaiton because its a key features in determining the expansion of the curve and how it's shaped along the values of features. Also in our dataset, the range of confidence interval is the lowest for standard deviation and hence its an important features.\n",
    "\n",
    "2) Median because its range of confidence interval is also among the smallest and median gives how skewed the distribution is,and represents the half of dataset and therefore gives a better perspective of the data. .\n",
    "\n",
    "3) Mean because it gives the information about the position of peak of the distribution and the type of distribution and in our dataset its range for confidence interval is among the smallest ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4\n",
    "I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. (Y = β0 + β1X + β2X2 + β3X3 + e)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One would expect that the training RSS of the cubic regression to be lower than the RSS of the linear regression because the training RSS always goes down when the model flexibility goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the expected RSS of the linear regression should be lower because the cubic regression would have a higher variance, which would not be offsetted by a reduction in bias (since the “true model” is actually linear)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as (a). One would expect that the training RSS of the cubic regression to be lower than the RSS of the linear regression because the training RSS always goes down when the model flexibility goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would depend on how non-linear is the true relationship between X and Y. If it’s just cuadratic, either the linear model or the cubic model could have a lower training RSS. However, if the true relationship is very far from linear, then one expect the cubic regression RSS to be lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
